# 模型配置调研报告

> Engram 需要使用酒馆的模型配置（API URL、Key、temperature 等）调用 LLM，但不使用酒馆的预设文本管理。本文档调研酒馆的 API 连接配置和模型参数获取方式。

---

## 1. 酒馆的 API 连接配置系统

### 1.1 Connection Profiles（连接配置文件）

酒馆通过 `connection-manager` 扩展管理 API 连接配置：

```typescript
// ConnectionProfile 结构
type ConnectionProfile = {
  id: string;           // 唯一标识
  mode: 'cc' | 'tc';    // cc=Chat Completion, tc=Text Completion
  name: string;         // 配置名称
  
  // API 配置
  api: string;          // API 类型 (openai, anthropic, etc.)
  'api-url': string;    // API 端点 URL
  model: string;        // 模型名称
  preset: string;       // 预设名称
  proxy: string;        // 代理配置
  'secret-id': string;  // Secret Key ID
  
  // 其他配置
  'instruct': string;      // Instruct 模板
  'context': string;       // Context 模板
  'tokenizer': string;     // 分词器
  'stop-strings': string;  // 停止字符串
  'reasoning-template': string; // 推理模板
  'regex-preset': string;  // 正则预设
  
  exclude: string[];    // 排除的配置项
};
```

### 1.2 获取当前连接配置

```javascript
import { extension_settings } from '../extensions.js';

// 获取所有配置
const profiles = extension_settings.connectionManager?.profiles || [];

// 获取当前选中的配置
const selectedId = extension_settings.connectionManager?.selectedProfile;
const currentProfile = profiles.find(p => p.id === selectedId);

// 通过斜线命令获取
const profileName = await SlashCommandParser.commands['profile'].callback({}, '');
```

### 1.3 Connection Profile 包含的配置项

| 字段 | 说明 | 示例值 |
|------|------|--------|
| `api` | API 类型 | `openai`, `anthropic`, `openrouter` |
| `api-url` | API 端点 | `https://api.openai.com/v1` |
| `model` | 模型名称 | `gpt-4o`, `claude-3-opus` |
| `preset` | 预设名称 | `Default`, `Creative` |
| `proxy` | 代理预设 | `MyProxy` |
| `secret-id` | API Key 标识 | `uuid-xxxx` |

---

## 2. 酒馆助手的自定义 API 配置

### 2.1 CustomApiConfig 类型

酒馆助手提供了完全独立于酒馆设置的 API 配置方式：

```typescript
type CustomApiConfig = {
  // 必填
  apiurl: string;       // API 端点 URL
  model: string;        // 模型名称
  
  // 可选
  key?: string;         // API Key
  source?: string;      // API 类型，默认 'openai'
  
  // 模型参数
  max_tokens?: number;        // 最大回复 tokens
  temperature?: number;       // 温度 (0-2)
  frequency_penalty?: number; // 频率惩罚 (-2 到 2)
  presence_penalty?: number;  // 存在惩罚 (-2 到 2)
  top_p?: number;             // Top-P 采样 (0-1)
};
```

### 2.2 使用 custom_api 调用 LLM

```javascript
// 完全独立于酒馆设置，使用自定义 API 配置
const result = await window.TavernHelper.generate({
  user_input: '请总结以下内容...',
  custom_api: {
    apiurl: 'https://api.openai.com/v1',
    key: 'sk-xxx',
    model: 'gpt-4o-mini',
    source: 'openai',
    
    // 采样参数
    max_tokens: 2048,
    temperature: 0.7,
    top_p: 0.95,
    frequency_penalty: 0,
    presence_penalty: 0
  }
});
```

### 2.3 generateRaw 完全自定义提示词

```javascript
// 不使用酒馆预设，完全自定义提示词顺序
const result = await window.TavernHelper.generateRaw({
  ordered_prompts: [
    { role: 'system', content: 'You are a helpful assistant.' },
    { role: 'user', content: '请总结这段内容' }
  ],
  custom_api: {
    apiurl: 'https://api.openai.com/v1',
    key: 'sk-xxx',
    model: 'gpt-4o-mini',
    temperature: 0.3  // 总结任务用较低温度
  }
});
```

---

## 3. 获取酒馆当前的模型设置

### 3.1 OpenAI/Chat Completion 设置

```javascript
import { oai_settings } from '../openai.js';

// 当前模型参数
const settings = {
  model: oai_settings.chat_completion_model,
  temperature: oai_settings.temp_openai,
  top_p: oai_settings.top_p_openai,
  frequency_penalty: oai_settings.freq_pen_openai,
  presence_penalty: oai_settings.pres_pen_openai,
  max_tokens: oai_settings.openai_max_tokens,
  max_context: oai_settings.openai_max_context,
};
```

### 3.2 通过 getContext 获取

```javascript
import { getContext } from '../extensions.js';

const context = getContext();

// 当前 API 类型
const apiType = context.mainApi;  // 'openai', 'kobold', etc.

// 最大上下文长度
const maxContext = context.maxContext;

// 当前聊天
const chat = context.chat;
```

### 3.3 通过斜线命令获取

```javascript
// 获取当前模型
const model = await SlashCommandParser.commands['model'].callback({}, '');

// 获取当前 API
const api = await SlashCommandParser.commands['api'].callback({}, '');

// 获取当前预设
const preset = await SlashCommandParser.commands['preset'].callback({}, '');
```

---

## 4. Engram 集成方案

### 4.1 使用酒馆当前配置 + 部分覆盖

```javascript
// 使用酒馆当前 API 配置，但覆盖模型参数
const result = await window.TavernHelper.generate({
  user_input: '请总结以下内容...',
  
  // 不使用酒馆预设的提示词，只用我们自己的
  overrides: {
    char_description: '',
    persona_description: '',
    world_info_before: '',
    world_info_after: '',
    scenario: '',
    dialogue_examples: '',
    chat_history: {
      prompts: [
        { role: 'system', content: engramSystemPrompt },
        { role: 'user', content: contentToSummarize }
      ]
    }
  },
  max_chat_history: 0  // 不使用聊天历史
});
```

### 4.2 完全使用自定义 API 配置

```javascript
// Engram 的 LLM 调用封装
class EngramLLMAdapter {
  constructor(config) {
    this.config = config;  // Engram 自己的配置
  }
  
  async summarize(content) {
    return await window.TavernHelper.generateRaw({
      ordered_prompts: [
        { role: 'system', content: this.getSummarizePrompt() },
        { role: 'user', content }
      ],
      custom_api: this.getApiConfig()
    });
  }
  
  getApiConfig() {
    return {
      apiurl: this.config.apiUrl,
      key: this.config.apiKey,
      model: this.config.model,
      temperature: this.config.temperature || 0.3,
      max_tokens: this.config.maxTokens || 2048
    };
  }
}
```

### 4.3 混合使用：酒馆 API + 自定义提示词 + 世界书

```javascript
import { getWorldInfoPrompt } from '../world-info.js';
import { substituteParams } from '../script.js';
import { getRegexedString, regex_placement } from '../extensions/regex/engine.js';

async function engramLLMCall(task, content, options = {}) {
  // 1. 获取世界书内容
  const chat = getContext().chat.map(m => m.mes).reverse();
  const wi = await getWorldInfoPrompt(chat, 8192, true, { trigger: 'normal' });
  const worldInfo = `${wi.worldInfoBefore}\n${wi.worldInfoAfter}`.trim();
  
  // 2. 宏替换
  const systemPrompt = substituteParams(options.systemPrompt || getDefaultPrompt(task));
  
  // 3. 构建提示词
  const prompts = [];
  
  // 添加世界书设定
  if (worldInfo && options.includeWorldInfo !== false) {
    prompts.push({ role: 'system', content: `[角色设定]\n${worldInfo}` });
  }
  
  // 添加系统提示
  prompts.push({ role: 'system', content: systemPrompt });
  
  // 添加内容
  prompts.push({ role: 'user', content });
  
  // 4. 调用 LLM（使用酒馆当前 API 设置）
  const result = await window.TavernHelper.generateRaw({
    ordered_prompts: prompts,
    max_chat_history: 0,
    // 如果 Engram 有自己的 API 配置，使用 custom_api
    ...(options.customApi ? { custom_api: options.customApi } : {})
  });
  
  // 5. 正则处理（可选）
  if (options.applyRegex) {
    return getRegexedString(result, regex_placement.AI_OUTPUT, { isPrompt: true });
  }
  
  return result;
}
```

---

## 5. Engram API 管理系统建议

### 5.1 配置结构

```typescript
interface EngramApiConfig {
  // 使用酒馆配置还是自定义配置
  useProfile: 'tavern' | 'custom';
  
  // 自定义 API 配置
  custom?: {
    apiUrl: string;
    apiKey: string;
    model: string;
    source: 'openai' | 'anthropic' | 'ollama' | 'vllm';
  };
  
  // 模型参数（无论使用哪个配置都生效）
  parameters: {
    temperature: number;
    topP: number;
    maxTokens: number;
    frequencyPenalty: number;
    presencePenalty: number;
  };
  
  // 上下文设置
  context: {
    maxChatHistory: number;        // 使用多少条聊天历史
    includeWorldInfo: boolean;     // 是否包含世界书
    worldInfoBudget: number;       // 世界书 token 预算
  };
  
  // RAG 相关
  rag: {
    vectorSource: 'transformers' | 'openai' | 'ollama' | 'vllm';
    rerankEnabled: boolean;
    rerankModel: string;
    topK: number;
  };
}
```

### 5.2 使用示例

```javascript
// Engram 配置
const engramConfig = {
  useProfile: 'tavern',  // 使用酒馆当前 API
  parameters: {
    temperature: 0.3,    // 覆盖温度
    maxTokens: 2048
  },
  context: {
    maxChatHistory: 10,
    includeWorldInfo: true
  }
};

// 或者完全自定义
const customConfig = {
  useProfile: 'custom',
  custom: {
    apiUrl: 'https://api.siliconflow.cn/v1',
    apiKey: 'sk-xxx',
    model: 'Qwen/Qwen2.5-7B-Instruct',
    source: 'openai'
  },
  parameters: {
    temperature: 0.5,
    maxTokens: 4096
  }
};
```

---

## 6. 参考资源

- Connection Manager: `/public/scripts/extensions/connection-manager/index.js`
- OpenAI 设置: `/public/scripts/openai.js` (`oai_settings`)
- 酒馆助手 API: `window.TavernHelper.generate()`, `window.TavernHelper.generateRaw()`
- 斜线命令: `/api`, `/model`, `/preset`, `/profile`
